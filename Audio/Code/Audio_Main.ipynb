{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_ct7Ga4mf9E"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhZoOvgQl_ip"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA_RCvaYpyRO"
      },
      "source": [
        "## Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q61xPTxoY17",
        "outputId": "7d4bc6f7-b3a8-4acd-a0d5-2a51406cbb8d"
      },
      "outputs": [],
      "source": [
        "# 2.1 Unzip the dataset you‚Äôve uploaded\n",
        "import zipfile\n",
        "\n",
        "# adjust path if needed; here we assume RAVDESS.zip is in the notebook‚Äôs working dir\n",
        "with zipfile.ZipFile(\"RAVDESS.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"RAVDESS\")   # extracts into ./RAVDESS/\n",
        "\n",
        "# 2.2 Point to the extracted folder\n",
        "DATA_PATH = \"RAVDESS\"\n",
        "assert os.path.isdir(DATA_PATH), \"RAVDESS folder not found!\"\n",
        "\n",
        "# 2.3 Gather all .wav file paths\n",
        "all_files = [\n",
        "    os.path.join(DATA_PATH, actor_dir, file)\n",
        "    for actor_dir in os.listdir(DATA_PATH)\n",
        "    for file in os.listdir(os.path.join(DATA_PATH, actor_dir))\n",
        "    if file.endswith(\".wav\")\n",
        "]\n",
        "print(f\"Total audio files: {len(all_files)}\")\n",
        "\n",
        "# 2.4 Quick class‚Äêdistribution check\n",
        "def emotion_from_filename(fn):\n",
        "    code = fn.split(\"-\")[2]\n",
        "    return {\n",
        "        \"01\":\"neutral\",\"02\":\"calm\",\"03\":\"happy\",\"04\":\"sad\",\n",
        "        \"05\":\"angry\",\"06\":\"fearful\",\"07\":\"disgust\",\"08\":\"surprised\"\n",
        "    }[code]\n",
        "\n",
        "labels = [emotion_from_filename(f) for f in all_files]\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "print(\"Class distribution:\")\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"  {u}: {c}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fuGcYeowdY8"
      },
      "source": [
        "##  ===== üéß Visualizing One Audio Sample per Emotion ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oQFZ-ob1x135",
        "outputId": "a7d82853-2f2f-4c6a-b282-9f3cc6fcf999"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display, HTML\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"üéß Emotion Samples\\n\")\n",
        "\n",
        "seen = set()\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "for idx, (file, label) in enumerate(zip(all_files, labels)):\n",
        "    if label not in seen:\n",
        "        seen.add(label)\n",
        "\n",
        "        y, sr = librosa.load(file, sr=22050)\n",
        "\n",
        "        # Header for each emotion\n",
        "        display(HTML(f\"<h3>üéôÔ∏è Emotion: <span style='color:blue'>{label}</span></h3>\"))\n",
        "\n",
        "        # Audio Player\n",
        "        display(Audio(y, rate=sr))\n",
        "\n",
        "        # Plot\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 3))\n",
        "\n",
        "        # Waveform\n",
        "        librosa.display.waveshow(y, sr=sr, ax=ax[0])\n",
        "        ax[0].set_title(f'Waveform - {label}')\n",
        "        ax[0].set_xlabel(\"Time\")\n",
        "        ax[0].set_ylabel(\"Amplitude\")\n",
        "\n",
        "        # Spectrogram\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "        img = librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel', ax=ax[1])\n",
        "        ax[1].set_title(f'Mel Spectrogram - {label}')\n",
        "        fig.colorbar(img, ax=ax[1], format=\"%+2.0f dB\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    if len(seen) == len(np.unique(labels)):\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07SFZEJxp6Ya"
      },
      "source": [
        "## Audio Preprocessing & Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkxlGB3bowCQ"
      },
      "outputs": [],
      "source": [
        "SAMPLE_RATE = 22050\n",
        "DURATION = 3        # seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
        "\n",
        "def extract_log_mel_spectrogram(file_path, n_mels=128):\n",
        "    y, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
        "    if len(y) < SAMPLES_PER_TRACK:\n",
        "        y = np.pad(y, (0, SAMPLES_PER_TRACK - len(y)))\n",
        "    else:\n",
        "        y = y[:SAMPLES_PER_TRACK]\n",
        "    # The librosa.feature.melspectrogram function expects keyword arguments\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return log_mel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pGUCWlhp-Fn"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uopVJkboyq0"
      },
      "outputs": [],
      "source": [
        "X, y = [], []\n",
        "for f in all_files:\n",
        "    X.append(extract_log_mel_spectrogram(f))\n",
        "    y.append(emotion_from_filename(f))\n",
        "\n",
        "X = np.array(X)[..., np.newaxis]   # shape: (N, n_mels, T, 1)\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "y_cat = tf.keras.utils.to_categorical(y_enc)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_cat,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_enc\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_JpiP1Srd9J"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "13CRwleYqA5A",
        "outputId": "0ed8a53a-f466-4cf7-ac40-2f26304ecd6e"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "input_shape = X_train.shape[1:]   # (n_mels, T, 1)\n",
        "num_classes = y_cat.shape[1]\n",
        "model = build_model(input_shape, num_classes)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIlJkx7Irg5K"
      },
      "source": [
        "## Training & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roNVlJeMqGFJ",
        "outputId": "dd0a2292-8a1f-4b89-df72-491d145a35b5"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.5, patience=5\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK-or-Dtrm3a"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1elpEBUYql_h",
        "outputId": "e540aead-7ef2-44bd-8f63-f2416fa781eb"
      },
      "outputs": [],
      "source": [
        "# 7. EVALUATION\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 7.1 Evaluate model to get test loss & accuracy\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss:     {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# 7.2 Inference on test set\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# 7.3 Compute precision, recall, F1-score (weighted) and display classification report\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pred, average='weighted'\n",
        ")\n",
        "print(f\"Precision:     {prec:.4f}\")\n",
        "print(f\"Recall:        {rec:.4f}\")\n",
        "print(f\"F1-score:      {f1:.4f}\\n\")\n",
        "\n",
        "# Detailed per-class report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(\n",
        "    y_true, y_pred,\n",
        "    target_names=le.classes_\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A-rxEPhytnx",
        "outputId": "c05f284f-216f-4825-a896-a52322c83ef3"
      },
      "outputs": [],
      "source": [
        "best_train_acc = max(history.history['accuracy'])\n",
        "best_train_epoch = history.history['accuracy'].index(best_train_acc) + 1\n",
        "\n",
        "lowest_train_loss = min(history.history['loss'])\n",
        "lowest_train_epoch = history.history['loss'].index(lowest_train_loss) + 1\n",
        "\n",
        "best_val_acc = max(history.history['val_accuracy'])\n",
        "best_val_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
        "\n",
        "lowest_val_loss = min(history.history['val_loss'])\n",
        "lowest_val_epoch = history.history['val_loss'].index(lowest_val_loss) + 1\n",
        "\n",
        "print(f\"Best Training Accuracy: {best_train_acc:.4f} at epoch {best_train_epoch}\")\n",
        "print(f\"Lowest Training Loss: {lowest_train_loss:.4f} at epoch {lowest_train_epoch}\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.4f} at epoch {best_val_epoch}\")\n",
        "print(f\"Lowest Validation Loss: {lowest_val_loss:.4f} at epoch {lowest_val_epoch}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvJ1YLgzta1D",
        "outputId": "b2c53ebf-58bc-4806-c1d9-9bf33dafcb6c"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# 1) Convert training history to an epoch-wise list of dictionaries\n",
        "epoch_data = []\n",
        "num_epochs = len(history.history['loss'])\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    epoch_info = {\n",
        "        \"epoch\":        i + 1,\n",
        "        \"loss\":         history.history['loss'][i],\n",
        "        \"accuracy\":     history.history['accuracy'][i],\n",
        "        \"val_loss\":     history.history['val_loss'][i],\n",
        "        \"val_accuracy\": history.history['val_accuracy'][i]\n",
        "    }\n",
        "    epoch_data.append(epoch_info)\n",
        "\n",
        "# 2) Evaluate on the test set to get final test loss & accuracy\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "final_results = {\n",
        "    \"test_loss\":     test_loss,\n",
        "    \"test_accuracy\": test_acc\n",
        "}\n",
        "\n",
        "# 3) Combine into one dictionary\n",
        "output = {\n",
        "    \"training_history\":   epoch_data,\n",
        "    \"final_evaluation\":   final_results\n",
        "}\n",
        "\n",
        "# 4) Save to JSON file\n",
        "with open(\"cnn_training_summary.json\", \"w\") as f:\n",
        "    json.dump(output, f, indent=4)\n",
        "\n",
        "print(\"Saved training+evaluation summary to cnn_training_summary.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jiw8_NfLrpWu"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P6CiyNOPq4c5",
        "outputId": "2c2bd72a-0bec-4b63-df85-f07a4e6b530b"
      },
      "outputs": [],
      "source": [
        "# 7.3 Enhanced Confusion Matrix Plot\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion Matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        fmt = '.2f'\n",
        "    else:\n",
        "        fmt = 'd'\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.0\n",
        "    # Annotate cells\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(\n",
        "            j, i, format(cm[i, j], fmt),\n",
        "            horizontalalignment='center',\n",
        "            color='white' if cm[i, j] > thresh else 'black'\n",
        "        )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Compute confusion matrix as before\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_names = le.classes_\n",
        "\n",
        "# Plot raw counts\n",
        "plot_confusion_matrix(cm, classes=class_names, normalize=False,\n",
        "                      title='Confusion Matrix (Counts)')\n",
        "\n",
        "# Plot normalized\n",
        "plot_confusion_matrix(cm, classes=class_names, normalize=True,\n",
        "                      title='Confusion Matrix (Normalized)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "SZY5s2-UzRkF",
        "outputId": "54f6e42e-4c6a-4879-b0f3-52640727f680"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set a different style for the plots (ggplot style)\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Create a figure with subplots for accuracy and loss\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Accuracy plot\n",
        "ax[0].plot(history.history['accuracy'], label='Train Accuracy', color='green', linestyle='-', marker='o', markersize=5)\n",
        "ax[0].plot(history.history['val_accuracy'], label='Val Accuracy', color='red', linestyle='--', marker='x', markersize=5)\n",
        "ax[0].set_title('Model Accuracy Over Epochs', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=14)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=14)\n",
        "ax[0].legend(loc='best')\n",
        "ax[0].grid(True, which='both', linestyle='-.', color='gray', alpha=0.7)\n",
        "\n",
        "# Loss plot\n",
        "ax[1].plot(history.history['loss'], label='Train Loss', color='blue', linestyle='-', marker='o', markersize=5)\n",
        "ax[1].plot(history.history['val_loss'], label='Val Loss', color='purple', linestyle='--', marker='x', markersize=5)\n",
        "ax[1].set_title('Model Loss Over Epochs', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=14)\n",
        "ax[1].set_ylabel('Loss', fontsize=14)\n",
        "ax[1].legend(loc='best')\n",
        "ax[1].grid(True, which='both', linestyle='-.', color='gray', alpha=0.7)\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA1LuM-Ar2Nd"
      },
      "source": [
        "##  Deployment Snippet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49RcVDgiq8Mh"
      },
      "outputs": [],
      "source": [
        "def predict_emotion(model, file_path):\n",
        "    \"\"\"\n",
        "    Given a trained model and a .wav file path,\n",
        "    returns the predicted emotion label.\n",
        "    \"\"\"\n",
        "    feat = extract_log_mel_spectrogram(file_path)\n",
        "    feat = feat[np.newaxis, ..., np.newaxis]  # shape: (1, n_mels, T, 1)\n",
        "    prob = model.predict(feat)[0]\n",
        "    idx = np.argmax(prob)\n",
        "    return le.inverse_transform([idx])[0]\n",
        "\n",
        "# Example:\n",
        "# print(predict_emotion(model, \"path_to_new_audio.wav\"))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
